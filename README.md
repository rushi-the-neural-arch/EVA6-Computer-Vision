

# Extensive Vision AI Program V6

Probably the most exhaustive and updated Deep Vision Program in the world! It is spread over three semester-style phases, each restricted by a qualifying exam. EVA6 will include Transformers and Attentions mechanism for Images!

![](https://github.com/rushirajsherlocked/EVA6-Computer-Vision/blob/main/Assg-3/EVAI6.jpg)

------

**Phase #1 - FUNDAMENTALS**

###### Lecture Title

| *Background & Basics*: Machine Learning Intuition            |
| ------------------------------------------------------------ |
| *Python*: Python 101 for Machine Learning                    |
| *DNN Concepts*: Convolutions, Pooling Operations & Channels  |
| *PyTorch*: Pytorch 101 for Vision Machine Learning           |
| *First Neural Network*: Kernels, Activations, and Layers     |
| *Architectural Basics*: We go through 9 model iterations together, step-by-step to find the final architecture |
| *BN, Kernels & Regularization*: Mathematics behind Batch Normalization, Kernel Initialization, and Regularization |
| *Advance Convolutions, Attention and Image Augmentation*: Depthwise, Pixel Shuffle, Dilated, Transpose, Channel Attention and Alnumentations Library |
| *Advanced Training Concepts*: Class Activation Maps, Optimizers, LR Schedules, LR Finder & One Cycle Policy |
| *ResNets*: Training ResNet for TinyImageNet from scratch     |
| *Object Detection YoloV2/V3/V4*: Understanding YOLO Loss Function & Training Yolo |
| *The Dawn Of Transformers*: Convolutions, Transformers and Types of Attention (Soft, Spatial, Channel, Self and Multi-head) |
| *HandsOn*: Transformers and Attention Mechanism              |
| *HandsOn*: Vision Transformers (ViT)                         |
| *Modern Object Detection*: End-To-End Object Detection with Transformers |
| *CapStone*: Qualifying Project for Phase 2                   |

